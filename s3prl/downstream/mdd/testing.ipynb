{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import L2ArcticDataset\n",
    "from model import Model\n",
    "from speechbrain.utils.edit_distance import wer_details_for_batch, alignment, op_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('=', 0, 0), ('=', 1, 1), ('I', None, 2), ('=', 2, 3), ('=', 3, 4), ('D', 4, None)]\n",
      "[('=', 0, 0), ('=', 1, 1)]\n"
     ]
    }
   ],
   "source": [
    "ids = [[\"utt1\"], [\"utt2\"]]\n",
    "refs = [[[\"a\", \"b\", \"c\", \"d\", \"d\"]], [[\"d\", \"e\"]]]\n",
    "hyps = [[[\"a\", \"b\", \"d\", \"c\", \"d\"]], [[\"d\", \"e\"]]]\n",
    "wer_details = []\n",
    "for ids_batch, refs_batch, hyps_batch in zip(ids, refs, hyps):\n",
    "    details = wer_details_for_batch(\n",
    "        ids_batch, refs_batch, hyps_batch, compute_alignments=True\n",
    "    )\n",
    "    wer_details.extend(details)\n",
    "print(wer_details[0][\"alignment\"])\n",
    "print(wer_details[1][\"alignment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping malformatted TextGrid file: /home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/l2arctic_release_v5.0/YDCK/annotation/arctic_a0272.TextGrid\n",
      "Skipping malformatted TextGrid file: /home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/l2arctic_release_v5.0/YDCK/annotation/arctic_a0209.TextGrid\n"
     ]
    }
   ],
   "source": [
    "data = L2ArcticDataset(\n",
    "    \"train\",\n",
    "    \"/home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/l2arctic_release_v5.0\", \n",
    "    \"./data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-6.8054e-03, -7.1716e-03, -6.6833e-03,  ...,  7.6294e-04,\n",
       "          3.0518e-05,  1.2207e-04]),\n",
       " tensor([ 0, 12, 35, 12, 42,  0, 23,  9, 39, 45,  1, 48, 40,  3, 34, 43, 12, 36,\n",
       "         23,  2, 42,  0, 45,  4, 48,  4, 33, 34, 15, 40, 42,  0, 42, 39,  2, 31,\n",
       "          3, 22, 14,  0,  0]),\n",
       " tensor([ 0,  9, 35,  9, 42,  0, 48,  9, 39, 45,  1, 48, 40,  3, 34, 43, 12, 36,\n",
       "         48,  2, 42,  0, 45,  4, 48,  4, 33, 34, 15, 40, 42,  0, 42, 39,  2, 31,\n",
       "          3, 22, 14,  0,  0]),\n",
       " 41,\n",
       " 41)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.0179, 0.0180, 0.0183,  ..., 0.0058, 0.0063, 0.0069]),\n",
       "  tensor([30, 14, 45, 11, 22, 12, 22, 12, 35, 42, 18, 23,  3,  9, 31,  0,  3, 44,\n",
       "          23,  3, 45,  4, 42, 10,  0,  3, 35, 22, 20, 12, 29,  2, 35,  0, 40, 32,\n",
       "          39,  3, 20, 12, 36,  0, 30, 12, 34, 40,  9, 33, 28,  0]),\n",
       "  tensor([30, 14, 45, 11, 22, 12, 22, 12, 35, 42, 18, 23,  3,  9, 31,  0,  3, 44,\n",
       "          23,  3, 45, 15, 42, 10,  0,  3, 35, 22, 20, 12, 29,  2, 35,  0, 40, 32,\n",
       "          39,  3, 20, 12, 36, 32, 30, 12, 34, 40,  9, 33, 28,  0]),\n",
       "  50,\n",
       "  50),\n",
       " (tensor([0.0110, 0.0099, 0.0096,  ..., 0.0204, 0.0207, 0.0198]),\n",
       "  tensor([47, 18, 34,  3, 40, 42,  0, 40, 33, 14, 37,  0, 30, 14, 10, 31, 22,  0,\n",
       "           0]),\n",
       "  tensor([47, 18, 34,  3, 40,  0,  3, 40, 33, 14, 37,  0, 30, 14, 10, 49, 22,  0,\n",
       "           0]),\n",
       "  19,\n",
       "  19),\n",
       " (tensor([-6.8054e-03, -7.1716e-03, -6.6833e-03,  ...,  7.6294e-04,\n",
       "           3.0518e-05,  1.2207e-04]),\n",
       "  tensor([ 0, 12, 35, 12, 42,  0, 23,  9, 39, 45,  1, 48, 40,  3, 34, 43, 12, 36,\n",
       "          23,  2, 42,  0, 45,  4, 48,  4, 33, 34, 15, 40, 42,  0, 42, 39,  2, 31,\n",
       "           3, 22, 14,  0,  0]),\n",
       "  tensor([ 0,  9, 35,  9, 42,  0, 48,  9, 39, 45,  1, 48, 40,  3, 34, 43, 12, 36,\n",
       "          48,  2, 42,  0, 45,  4, 48,  4, 33, 34, 15, 40, 42,  0, 42, 39,  2, 31,\n",
       "           3, 22, 14,  0,  0]),\n",
       "  41,\n",
       "  41)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "list(torch.utils.data.Subset(data, np.arange(1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    data,\n",
    "    batch_size=4,  # for bucketing\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    "    collate_fn=data.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([ 0.0046,  0.0045,  0.0042,  ..., -0.0015, -0.0016, -0.0017]),\n",
       "  tensor([-0.0011, -0.0011, -0.0015,  ...,  0.0027,  0.0028,  0.0031]),\n",
       "  tensor([-0.0042, -0.0040, -0.0038,  ...,  0.0081,  0.0080,  0.0083]),\n",
       "  tensor([0.0093, 0.0096, 0.0103,  ..., 0.0249, 0.0245, 0.0255])],\n",
       " tensor([[ 0,  8, 32, 11, 34, 28,  4, 39, 12, 35, 28,  4, 39, 34, 11, 41,  3, 35,\n",
       "           0, 34,  4, 39,  5, 42,  3, 44, 32, 47, 17, 39, 14,  1, 40,  3, 42, 14,\n",
       "          23,  3, 35,  9, 35, 14, 43, 12, 36,  9, 33, 40,  0,  0],\n",
       "         [ 0, 34, 14, 35, 45,  8, 33,  8, 33, 29, 15,  5, 42, 42,  3, 20, 39, 14,\n",
       "          23,  0,  3, 40, 37,  9, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 23,  9, 35,  0,  3, 35, 22,  2, 42,  0,  0, 40,  3, 37, 10,  0, 30,\n",
       "          14, 42, 39,  8, 22, 42,  3, 28,  2, 23,  3, 34, 30, 10,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [30, 14, 45,  9, 35, 42, 22,  5, 35,  0, 12, 35, 34, 12, 22, 40, 42, 39,\n",
       "          14, 34,  0, 40, 10, 21, 12, 36, 23,  3, 41,  2, 22, 15, 48,  3, 44,  0,\n",
       "          20, 15, 43,  0, 41,  4, 39, 48,  0,  0,  0,  0,  0,  0]]),\n",
       " tensor([[ 0,  8, 29, 11, 34, 28,  4, 39, 12, 35, 28,  4,  0, 34, 11, 41,  3, 35,\n",
       "           0, 34,  4, 39,  5, 42,  4, 44, 32, 47, 17, 39, 14,  1, 40,  3, 42, 14,\n",
       "          22,  3, 35,  9, 35, 14, 42, 12, 36,  9, 33, 40,  0,  0],\n",
       "         [ 0, 34, 14, 35, 45,  8,  0,  8,  0, 29, 15,  5, 42, 42,  3, 20, 39, 14,\n",
       "          43,  0,  3, 40, 37,  9, 45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 22,  9, 35,  0,  0,  0,  0,  2, 42,  0,  3, 40, 18, 20, 10,  0, 30,\n",
       "          14, 42, 39,  8, 22, 42,  3, 28,  1, 22,  3, 34, 30, 10,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [30, 14, 45,  9, 35,  0, 22,  5, 35,  0, 14, 35, 34, 12, 35, 40, 42, 39,\n",
       "          14, 34,  0, 40, 10, 21, 12, 35, 23,  3, 41,  2, 22, 15, 40,  3, 44,  0,\n",
       "          20, 15, 23,  0, 41,  4, 39, 40,  0,  0,  0,  0,  0,  0]]),\n",
       " tensor([50, 26, 34, 46]),\n",
       " tensor([50, 26, 34, 46])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in loader:\n",
    "    display(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/712 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0051, -0.0047, -0.0052,  ..., -0.0145, -0.0143, -0.0143]),\n",
       " tensor([-0.0043, -0.0045, -0.0048,  ...,  0.0191,  0.0190,  0.0188]),\n",
       " tensor([-0.0018, -0.0009, -0.0022,  ...,  0.0029,  0.0038,  0.0030]),\n",
       " tensor([ 6.1035e-05, -1.5259e-04,  1.2207e-04,  ...,  2.0508e-02,\n",
       "          2.0874e-02,  2.0935e-02])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 41, 14, 42,  0, 10, 35, 22,  0, 12, 35,  2, 42, 23, 14, 30, 15, 42,\n",
       "          9, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 40,  3, 37, 15, 48, 47, 18, 40,  4, 34, 14,  2, 42, 45, 10, 32, 43,\n",
       "         39, 18, 23,  3, 45, 12, 35, 22, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 30, 14, 30,  2, 22,  0, 37, 14, 33, 22,  4, 28,  0, 30, 12, 48, 41,\n",
       "         10, 42,  2, 35, 22, 45,  4, 48, 45,  8, 33, 22, 33, 14,  0, 45, 11, 44,\n",
       "         12, 36, 12, 42,  0,  0],\n",
       "        [ 0, 41, 14, 42, 10, 35, 22,  0, 12, 35,  2, 42, 23, 14, 30, 15, 42,  9,\n",
       "         33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 41, 14, 42,  4, 10, 35, 22,  0, 12, 35,  2,  0, 23, 14, 30,  4, 42,\n",
       "          9, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 40,  3, 20, 15, 40, 47, 18, 40,  4, 34, 14,  2, 42, 44,  3, 32, 42,\n",
       "         39, 18, 22,  3, 45, 12, 35, 22, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 30, 14, 30,  9, 42,  0, 37, 14, 18,  0,  4, 28,  0, 30, 12, 48, 41,\n",
       "         17, 42,  9, 35,  0, 45,  4,  0, 45,  8,  0, 22, 33, 14, 29, 45, 11, 44,\n",
       "         12, 35, 12, 42,  0,  0],\n",
       "        [ 0, 41, 14, 42, 10, 35, 22,  0, 14, 35,  2, 42, 22, 14, 30, 15, 42,  9,\n",
       "         33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([21, 29, 42, 21])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([21, 29, 42, 21])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/712 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch_id, (wav_view, *others) in enumerate(tqdm(loader, dynamic_ncols=True, desc='train')):\n",
    "    display(batch_id)\n",
    "    display(wav_view)\n",
    "    display(*others)\n",
    "    break\n",
    "    # print(*others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0026, -0.0026, -0.0024,  ...,  0.0006,  0.0004,  0.0002]),\n",
       " tensor([30, 14, 45, 12, 33, 28,  1, 33, 15,  3, 40, 40, 18, 35,  0,  0]),\n",
       " tensor([30, 14, 45, 12, 33, 28,  1, 33,  4,  3, 40, 40, 18, 35,  0,  0]),\n",
       " 16,\n",
       " 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/xt0r3-user/cambridge/partii/dissertation/s3prl/s3prl/s3prl/downstream/mdd/testing.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xt0r3-user/cambridge/partii/dissertation/s3prl/s3prl/s3prl/downstream/mdd/testing.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data[\u001b[39m3\u001b[39;49m:\u001b[39m5\u001b[39;49m]\n",
      "File \u001b[0;32m~/cambridge/partii/dissertation/s3prl/s3prl/s3prl/downstream/mdd/dataset.py:136\u001b[0m, in \u001b[0;36mL2ArcticDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m--> 136\u001b[0m     item_root \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem_paths[index][\u001b[39m\"\u001b[39;49m\u001b[39mitem_root\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    137\u001b[0m     item_stem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_paths[index][\u001b[39m\"\u001b[39m\u001b[39mitem_stem\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    139\u001b[0m     wav_view \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_wav(item_root \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwav/\u001b[39m\u001b[39m{\u001b[39;00mitem_stem\u001b[39m}\u001b[39;00m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "data[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model = Model(\n",
    "    input_dim=self.upstream_dim,\n",
    "    output_class_num=self.dataset['train'].output_class_num\n",
    "    **self.modelrc,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

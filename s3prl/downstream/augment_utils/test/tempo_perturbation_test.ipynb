{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from s3prl.downstream.augment_utils.tempo_perturbation import TempoPerturbation\n",
    "from s3prl.downstream.mdd.dataset import L2ArcticDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = L2ArcticDataset(\n",
    "    'train',\n",
    "    '/home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/l2arctic_release_v5.0',\n",
    "    '/home/xt0r3-user/cambridge/partii/dissertation/s3prl/s3prl/s3prl/downstream/mdd/data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(waveform, sample_rate):\n",
    "  waveform = waveform.numpy()\n",
    "  display(Audio(waveform, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = torchaudio.functional.resample(dataset[0][0], orig_freq=44100, new_freq=16000)\n",
    "\n",
    "\n",
    "play_audio(audio, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def _validate_audio(audio):\n",
    "    \"\"\"validate the input audio and modify the order of channels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    audio : numpy.ndarray [shape=(channel, num_samples) or (num_samples)\\\n",
    "                           or (num_samples, channel)]\n",
    "            the input audio sequence to validate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    audio : numpy.ndarray [shape=(channel, num_samples)]\n",
    "            the validataed output audio sequence.\n",
    "    \"\"\"\n",
    "    if audio.ndim == 1:\n",
    "        audio = np.expand_dims(audio, 0)\n",
    "    elif audio.ndim > 2:\n",
    "        raise Exception(\"Please use the valid audio source. \"\n",
    "                        + \"Number of dimension of input should be less than 3.\")\n",
    "    elif audio.shape[0] > audio.shape[1]:\n",
    "        print('it seems that the 2nd axis of the input audio source '\n",
    "             + 'is a channel. it is recommended that fix channel '\n",
    "             + 'to the 1st axis.', stacklevel=3)\n",
    "        audio = audio.T\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "def _validate_scale_factor(audio, s):\n",
    "    \"\"\"Validate the scale factor s and\n",
    "    convert the fixed scale factor to anchor points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    audio : numpy.ndarray [shape=(num_channels, num_samples) \\\n",
    "                           or (num_samples) or (num_samples, num_channels)]\n",
    "            the input audio sequence.\n",
    "    s : number > 0 [scalar] or numpy.ndarray [shape=(2, num_points) \\\n",
    "        or (num_points, 2)]\n",
    "        the time stretching factor. Either a constant value (alpha)\n",
    "        or an (2 x n) (or (n x 2)) array of anchor points\n",
    "        which contains the sample points of the input signal in the first row\n",
    "        and the sample points of the output signal in the second row.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    anc_points : numpy.ndarray [shape=(2, num_points)]\n",
    "                 anchor points which contains the sample points\n",
    "                 of the input signal in the first row\n",
    "                 and the sample points of the output signal in the second row.\n",
    "    \"\"\"\n",
    "    if np.isscalar(s):\n",
    "        anc_points = np.array([[0, np.shape(audio)[1] - 1],\n",
    "                               [0, np.ceil(s * np.shape(audio)[1]) - 1]])\n",
    "    elif s.ndim == 2:\n",
    "        if s.shape[0] == 2:\n",
    "            anc_points = s\n",
    "        elif s.shape[1] == 2:\n",
    "            print('it seems that the anchor points '\n",
    "                 + 'has shape (num_points, 2). '\n",
    "                 + 'it is recommended to '\n",
    "                 + 'have shape (2, num_points).', stacklevel=3)\n",
    "            anc_points = s.T\n",
    "    else:\n",
    "        raise Exception('Please use the valid anchor points. '\n",
    "                        + '(scalar or pair of input/output sample points)')\n",
    "\n",
    "    return anc_points\n",
    "\n",
    "def wsola(x, s, win_type='hann',\n",
    "          win_size=1024, syn_hop_size=512, tolerance=512):\n",
    "    \"\"\"Modify length of the audio sequence using WSOLA algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    x : numpy.ndarray [shape=(channel, num_samples) or (num_samples)]\n",
    "        the input audio sequence to modify.\n",
    "    s : number > 0 [scalar] or numpy.ndarray [shape=(2, num_points)]\n",
    "        the time stretching factor. Either a constant value (alpha)\n",
    "        or an 2 x n array of anchor points which contains the sample points\n",
    "        of the input signal in the first row\n",
    "        and the sample points of the output signal in the second row.\n",
    "    win_type : str\n",
    "               type of the window function. hann and sin are available.\n",
    "    win_size : int > 0 [scalar]\n",
    "               size of the window function.\n",
    "    syn_hop_size : int > 0 [scalar]\n",
    "                   hop size of the synthesis window.\n",
    "                   Usually half of the window size.\n",
    "    tolerance : int >= 0 [scalar]\n",
    "                number of samples the window positions\n",
    "                in the input signal may be shifted\n",
    "                to avoid phase discontinuities when overlap-adding them\n",
    "                to form the output signal (given in samples).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    y : numpy.ndarray [shape=(channel, num_samples) or (num_samples)]\n",
    "        the modified output audio sequence.\n",
    "    \"\"\"\n",
    "    # validate the input audio and scale factor.\n",
    "    x = _validate_audio(x)\n",
    "    anc_points = _validate_scale_factor(x, s)\n",
    "\n",
    "    n_chan = x.shape[0]\n",
    "    output_length = int(anc_points[-1, -1]) + 1\n",
    "\n",
    "    display(f\"{output_length}\")\n",
    "\n",
    "\n",
    "\n",
    "    win = torch.hann_window(win_size).numpy()\n",
    "\n",
    "    sw_pos = np.arange(0, output_length + win_size // 2, syn_hop_size)\n",
    "    ana_interpolated = interp1d(anc_points[1, :], anc_points[0, :],\n",
    "                                fill_value='extrapolate')\n",
    "    aw_pos = np.round(ana_interpolated(sw_pos)).astype(int)\n",
    "\n",
    "    display(f\"{sw_pos=}\")\n",
    "    display(f\"{sw_pos.shape=}\")\n",
    "    display(f\"{aw_pos=}\")\n",
    "    display(f\"{aw_pos.shape=}\")\n",
    "\n",
    "    ana_hop = np.insert(aw_pos[1:] - aw_pos[0: -1], 0, 0)\n",
    "\n",
    "    display(f\"{ana_hop=}\")\n",
    "\n",
    "    y = np.zeros((n_chan, output_length))\n",
    "\n",
    "    min_fac = np.min(syn_hop_size / ana_hop[1:])\n",
    "\n",
    "    # padding the input audio sequence.\n",
    "    left_pad = int(win_size // 2 + tolerance)\n",
    "    right_pad = int(np.ceil(1 / min_fac) * win_size + tolerance)\n",
    "    x_padded = np.pad(x, ((0, 0), (left_pad, right_pad)), 'constant')\n",
    "\n",
    "    aw_pos = aw_pos + tolerance\n",
    "\n",
    "    # Applying WSOLA to each channels\n",
    "    for c, x_chan in enumerate(x_padded):\n",
    "        y_chan = np.zeros(output_length + 2 * win_size)\n",
    "        ow = np.zeros(output_length + 2 * win_size)\n",
    "\n",
    "        delta = 0\n",
    "\n",
    "        for i in range(len(aw_pos) - 1):\n",
    "            x_adj = x_chan[aw_pos[i] + delta: aw_pos[i] + win_size + delta]\n",
    "            y_chan[sw_pos[i]: sw_pos[i] + win_size] += x_adj * win\n",
    "            ow[sw_pos[i]: sw_pos[i] + win_size] += win\n",
    "\n",
    "            nat_prog = x_chan[aw_pos[i] + delta + syn_hop_size:\n",
    "                              aw_pos[i] + delta + syn_hop_size + win_size]\n",
    "\n",
    "            next_aw_range = np.arange(aw_pos[i+1] - tolerance,\n",
    "                                      aw_pos[i+1] + win_size + tolerance)\n",
    "\n",
    "            x_next = x_chan[next_aw_range]\n",
    "\n",
    "            cross_corr = np.correlate(nat_prog, x_next)\n",
    "            print(f\"{cross_corr=}\")\n",
    "            print(f\"{cross_corr.shape=}\")\n",
    "\n",
    "            max_index = np.argmax(cross_corr)\n",
    "\n",
    "            delta = tolerance - max_index\n",
    "\n",
    "        # Calculate last frame\n",
    "        x_adj = x_chan[aw_pos[-1] + delta: aw_pos[-1] + win_size + delta]\n",
    "        y_chan[sw_pos[-1]: sw_pos[-1] + win_size] += x_adj * win\n",
    "        ow[sw_pos[-1]: sw_pos[-1] + win_size] += + win\n",
    "\n",
    "        ow[ow < 1e-3] = 1\n",
    "\n",
    "        y_chan = y_chan / ow\n",
    "        y_chan = y_chan[win_size // 2:]\n",
    "        y_chan = y_chan[: output_length]\n",
    "\n",
    "        y[c, :] = y_chan\n",
    "\n",
    "    return y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(wsola(audio, 1.2), rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = TempoPerturbation(\n",
    "    N=1024,\n",
    "    sample_rate=16000,\n",
    "    alpha_high=1.2,\n",
    "    alpha_low=1.2,\n",
    "    delta_max=512,\n",
    "    prob=1.0,\n",
    ")\n",
    "play_audio(\n",
    "    augmentation(\n",
    "        [audio]\n",
    "    )[0],\n",
    "    sample_rate=16000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1, 6)\n",
    "v = np.arange(6, 8)\n",
    "np.correlate(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(a, dtype=int)\n",
    "w = torch.tensor(v, dtype=int)\n",
    "\n",
    "augmentation.cross_correlate(w, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsola(audio, 0.7) - augmentation(\n",
    "    [audio]\n",
    ")[0].numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

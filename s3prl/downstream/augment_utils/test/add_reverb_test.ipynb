{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3prl.downstream.mdd.dataset import L2ArcticDataset\n",
    "from s3prl.downstream.augment_utils.add_noise import AddNoise\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"/home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/rir/Audio\")\n",
    "\n",
    "wavs = []\n",
    "srs = []\n",
    "\n",
    "for path in folder.iterdir():\n",
    "    if path.suffix != \".wav\":\n",
    "        continue\n",
    "    wav, sr = torchaudio.load(path)\n",
    "    wav = wav.squeeze()\n",
    "    wav = wav / wav.norm()\n",
    "    wavs.append(wav)\n",
    "    srs.append(sr)\n",
    "sr = srs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot(wav, ax=None, **kwargs):\n",
    "    if ax is not None:\n",
    "        ax.plot(np.linspace(0, len(wav) / sr, wav.shape[-1]), wav, **kwargs)\n",
    "    else:\n",
    "        plt.plot(np.linspace(0, len(wav) / sr, wav.shape[-1]), wav, **kwargs)\n",
    "\n",
    "\n",
    "plot(wavs[3][: int(0.025 * sr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = L2ArcticDataset(\n",
    "    \"train\",\n",
    "    \"/home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/l2arctic_release_v5.0\",\n",
    "    \"/home/xt0r3-user/cambridge/partii/dissertation/s3prl/s3prl/s3prl/downstream/mdd/data/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "    display(Audio(waveform, rate=sample_rate))\n",
    "\n",
    "\n",
    "audio = [\n",
    "    torchaudio.functional.resample(dataset[0][0], orig_freq=44100, new_freq=16000),\n",
    "    torchaudio.functional.resample(dataset[1][0], orig_freq=44100, new_freq=16000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(torchaudio.functional.fftconvolve(audio[0], wavs[30]), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(torchaudio.functional.fftconvolve(audio[0], wavs[12]), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rev(x, **kwargs):\n",
    "    plot(torchaudio.functional.fftconvolve(audio[0], wavs[x]), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "def plot_shift(t):\n",
    "    mult = 2000\n",
    "    wav = wavs[1][239:]\n",
    "    sound = audio[0][: len(audio[0]) // 4]\n",
    "    if t != 0:\n",
    "        sound = sound[: -t * mult]\n",
    "    # if t == 0:\n",
    "    #     plt.plot(audio[0][t*mult:] * wavs[3][t], alpha=(wav / wav.max()).item())\n",
    "    # else:\n",
    "    plt.plot(\n",
    "        torch.cat([torch.zeros(t * mult), sound]),\n",
    "        alpha=min(1, (wav[t].abs() / wav.max()).item() + 0.2),\n",
    "    )\n",
    "\n",
    "\n",
    "for i in range(0, 6):\n",
    "    # [0, 1, 2, 3]\n",
    "    plot_shift(i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        f\"/home/xt0r3-user/cambridge/partii/dissertation/final/figs/chapter-3/reverb/rev_{i}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs[1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio[0][: len(audio[0]) // 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 5))\n",
    "plt.plot(\n",
    "    torchaudio.functional.fftconvolve(audio[0][: len(audio[0]) // 4], wavs[1][141:])[\n",
    "        : len(audio[0]) // 4\n",
    "    ]\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\n",
    "    f\"/home/xt0r3-user/cambridge/partii/dissertation/final/figs/chapter-3/reverb/result.png\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 5))\n",
    "plt.plot(audio[0][: len(audio[0]) // 4])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\n",
    "    f\"/home/xt0r3-user/cambridge/partii/dissertation/final/figs/chapter-3/reverb/start.png\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wavs[3][141:161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wavs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs[3].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs[3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rev(3)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax2 = plt.subplot(2, 2, 3)\n",
    "ax3 = plt.subplot(1, 2, 2)\n",
    "\n",
    "n = 12\n",
    "\n",
    "plot(wavs[n][: int(0.1 * sr)], ax=ax1)\n",
    "plot(audio[0], ax=ax2)\n",
    "plot_rev(n, ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = torch.Generator()\n",
    "rng.manual_seed(1337)\n",
    "n = 5\n",
    "indices = torch.randint(\n",
    "    0,\n",
    "    len(wavs),\n",
    "    (n,),\n",
    "    generator=rng,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2 * n))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.plot(torchaudio.functional.fftconvolve(audio[0], wavs[idx]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"wav_{i}.png\", bbox_inches=\"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 2))\n",
    "plt.plot(audio[0], color=\"k\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(f\"wav.png\", bbox_inches=\"tight\")\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

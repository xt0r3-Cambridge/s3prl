{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3prl.downstream.mdd.dataset import L2ArcticDataset\n",
    "from s3prl.downstream.augment_utils.add_noise import AddNoise\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path('/home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/rir/Audio')\n",
    "\n",
    "wavs = []\n",
    "srs = []\n",
    "\n",
    "for path in folder.iterdir():\n",
    "    if path.suffix != '.wav':\n",
    "        continue\n",
    "    wav, sr = torchaudio.load(path)\n",
    "    wav = wav.squeeze()\n",
    "    wav = wav / wav.norm()\n",
    "    wavs.append(wav)\n",
    "    srs.append(sr)\n",
    "sr = srs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot(wav):\n",
    "    plt.plot(np.linspace(0, len(wav) / sr, wav.shape[-1]), wav)\n",
    "\n",
    "plot(wavs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = L2ArcticDataset(\n",
    "    \"train\",\n",
    "    \"/home/xt0r3-user/cambridge/partii/dissertation/s3prl/data/l2arctic_release_v5.0\",\n",
    "    \"/home/xt0r3-user/cambridge/partii/dissertation/s3prl/s3prl/s3prl/downstream/mdd/data/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "    display(Audio(waveform, rate=sample_rate))\n",
    "\n",
    "\n",
    "audio = [\n",
    "    torchaudio.functional.resample(dataset[0][0], orig_freq=44100, new_freq=16000),\n",
    "    torchaudio.functional.resample(dataset[1][0], orig_freq=44100, new_freq=16000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(torchaudio.functional.fftconvolve(audio[0], wavs[30]), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(torchaudio.functional.fftconvolve(audio[0], wav[0]), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rev(x):\n",
    "    plot(torchaudio.functional.fftconvolve(audio[0], wavs[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = torch.Generator()\n",
    "rng.manual_seed(1337)\n",
    "n = 5\n",
    "indices = torch.randint(\n",
    "    0,\n",
    "    len(wavs),\n",
    "    (n,),\n",
    "    generator=rng,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2 * n))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.plot(torchaudio.functional.fftconvolve(audio[0], wavs[idx]))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"wav_{i}.png\", bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 2))\n",
    "plt.plot(audio[0], color='k')\n",
    "plt.axis('off')\n",
    "plt.savefig(f\"wav.png\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(audio[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio[0], 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = AddNoise(\n",
    "    prob=1.0,\n",
    "    snr_low=0,\n",
    "    snr_high=0.4,\n",
    "    device=\"cpu\",\n",
    "    seed=1337,\n",
    ")\n",
    "audio = torch.nn.utils.rnn.pad_sequence(audio, batch_first=True)\n",
    "lens = torch.tensor([len(audio[0]), len(audio[1])], dtype=torch.long)\n",
    "aug_audio =     augmentation(\n",
    "        audio,\n",
    "        lens,\n",
    "    )\n",
    "play_audio(\n",
    "    aug_audio[0],\n",
    "    sample_rate=16000,\n",
    ")\n",
    "\n",
    "audio - aug_audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
